{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from enum import IntEnum, Enum"
      ],
      "metadata": {
        "id": "A2BpANMrznNx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Action(Enum):\n",
        "  UP = 'U'\n",
        "  DOWN = 'D'\n",
        "  LEFT = 'L'\n",
        "  RIGHT = 'R'\n",
        "\n",
        "  def __str__(self):\n",
        "    return str(self.value)"
      ],
      "metadata": {
        "id": "oaOGC8bt14LN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(IntEnum):\n",
        "  ACCESSIBLE_GRID = 0\n",
        "  INACCESSIBLE_GRID = -2\n",
        "  LOSER_GRID = -1\n",
        "  WINNER_GRID = 1"
      ],
      "metadata": {
        "id": "HovS_zDS5LvC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ACTION_SPACE = (Action.UP, Action.DOWN, Action.LEFT, Action.RIGHT)\n",
        "STATE_PROBS = [0.6, 0.35, 0.05] # prob of accessible grid, prob of inaccessible grid, prob of loser grid\n",
        "STATES = [State.ACCESSIBLE_GRID, State.INACCESSIBLE_GRID, State.LOSER_GRID, State.WINNER_GRID]\n",
        "UNKNOWN_POLICY = -2 # the policy is unknown for now, the policies are going to be determined after creating the gridworld\n",
        "ROW_SIZE = 10\n",
        "COLUMN_SIZE = 10\n",
        "THRESHOLD = 1e-3\n",
        "DISCOUNT_FACTOR = 0.9"
      ],
      "metadata": {
        "id": "i3egGS_kzpis"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Gridworld: # Environment\n",
        "  def __init__(self, rows, cols, start):\n",
        "    self.rows = rows\n",
        "    self.cols = cols\n",
        "    self.i = start[0]\n",
        "    self.j = start[1]\n",
        "\n",
        "  def set(self, rewards, actions):\n",
        "    # rewards should be a dict of: (i, j): r (row, col): reward\n",
        "    # actions should be a dict of: (i, j): A (row, col): list of possible actions\n",
        "    self.rewards = rewards\n",
        "    self.actions = actions\n",
        "\n",
        "  def set_rewards(self, rewards):\n",
        "    # rewards should be a dict of: (i, j): r (row, col): reward\n",
        "    self.rewards = rewards\n",
        "\n",
        "  def set_actions(self, actions):\n",
        "    # actions should be a dict of: (i, j): A (row, col): list of possible actions\n",
        "    self.actions = actions\n",
        "\n",
        "  def set_state(self, s):\n",
        "    self.i = s[0]\n",
        "    self.j = s[1]\n",
        "\n",
        "  def current_state(self):\n",
        "    return (self.i, self.j)\n",
        "\n",
        "  def is_terminal(self, state):\n",
        "    return state not in self.actions\n",
        "\n",
        "  def reset(self):\n",
        "    # put agent back in start position\n",
        "    self.i = ROW_SIZE - 1\n",
        "    self.j = 0\n",
        "    return (self.i, self.j)\n",
        "\n",
        "  def get_next_state(self, state, action):\n",
        "    # this answers: where would I end up if I perform action 'action' in state 's'?\n",
        "    i, j = state[0], state[1]\n",
        "\n",
        "    # if this action moves you somewhere else, then it will be in this dictionary\n",
        "    if action == Action.UP:\n",
        "      i -= 1\n",
        "    elif action == Action.DOWN:\n",
        "      i += 1\n",
        "    elif action == Action.RIGHT:\n",
        "      j += 1\n",
        "    elif action == Action.LEFT:\n",
        "      j -= 1\n",
        "\n",
        "    return i, j\n",
        "\n",
        "  def move(self, action):\n",
        "    # check if legal move first\n",
        "    if action in self.actions[(self.i, self.j)]:\n",
        "      if action == Action.UP:\n",
        "        self.i -= 1\n",
        "      elif action == Action.DOWN:\n",
        "        self.i += 1\n",
        "      elif action == Action.RIGHT:\n",
        "        self.j += 1\n",
        "      elif action == Action.LEFT:\n",
        "        self.j -= 1\n",
        "    # return a reward (if any)\n",
        "    return self.rewards.get((self.i, self.j), 0)\n",
        "\n",
        "  def undo_move(self, action):\n",
        "    # these are the opposite of what U/D/L/R should normally do\n",
        "    if action == Action.UP:\n",
        "      self.i += 1\n",
        "    elif action == Action.DOWN:\n",
        "      self.i -= 1\n",
        "    elif action == Action.RIGHT:\n",
        "      self.j -= 1\n",
        "    elif action == Action.LEFT:\n",
        "      self.j += 1\n",
        "    # raise an exception if we arrive somewhere we shouldn't be\n",
        "    # should never happen\n",
        "    assert(self.current_state() in self.all_states())\n",
        "\n",
        "  def game_over(self):\n",
        "    # returns true if game is over, else false\n",
        "    # true if we are in a state where no actions are possible\n",
        "    return (self.i, self.j) not in self.actions\n",
        "\n",
        "  def all_states(self):\n",
        "    # possibly buggy but simple way to get all states\n",
        "    # either a position that has possible next actions\n",
        "    # or a position that yields a reward\n",
        "    return set(self.actions.keys()) | set(self.rewards.keys())"
      ],
      "metadata": {
        "id": "7fMc7cCCubT9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gridworld():\n",
        "  # define a grid that describes the reward for arriving at each state\n",
        "  # and possible actions at each state\n",
        "  gridworld = Gridworld(ROW_SIZE, COLUMN_SIZE, (ROW_SIZE, 0))\n",
        "\n",
        "  rewards = {}\n",
        "  actions = {}\n",
        "  total_number_of_grids = ROW_SIZE * COLUMN_SIZE\n",
        "  number_of_accessible_grid = int(total_number_of_grids * STATE_PROBS[State.ACCESSIBLE_GRID])\n",
        "  number_of_inaccessible_grid = int(total_number_of_grids * STATE_PROBS[State.INACCESSIBLE_GRID])\n",
        "  # We subtract the number of winner grid which is 1.\n",
        "  number_of_loser_grid = total_number_of_grids - number_of_accessible_grid - number_of_inaccessible_grid - 1\n",
        "\n",
        "  # populate the accessible grid\n",
        "  num_grid = 0\n",
        "  while num_grid < number_of_accessible_grid:\n",
        "    i = np.random.choice(ROW_SIZE)\n",
        "    j = np.random.choice(COLUMN_SIZE)\n",
        "    state = (i, j)\n",
        "    if state not in actions.keys():\n",
        "      num_grid += 1\n",
        "      actions[state] = None\n",
        "\n",
        "  # populate the negative reward grid\n",
        "  num_grid = 0\n",
        "  while num_grid < number_of_loser_grid:\n",
        "    i = np.random.choice(ROW_SIZE)\n",
        "    j = np.random.choice(COLUMN_SIZE)\n",
        "    state = (i, j)\n",
        "    if state not in actions.keys() and state not in rewards.keys():\n",
        "      num_grid += 1\n",
        "      rewards[state] = -10\n",
        "\n",
        "  # populate the positive reward grid\n",
        "  num_grid = 0\n",
        "  while num_grid < 1:\n",
        "    i = np.random.choice(ROW_SIZE)\n",
        "    j = np.random.choice(COLUMN_SIZE)\n",
        "    state = (i, j)\n",
        "    if state not in actions.keys() and state not in rewards.keys():\n",
        "      num_grid += 1\n",
        "      rewards[state] = 10\n",
        "\n",
        "  gridworld.set_rewards(rewards)\n",
        "  gridworld.set_actions(actions)\n",
        "\n",
        "  # populate action space\n",
        "  for key, _ in actions.items():\n",
        "    actions_ = []\n",
        "    for action in ACTION_SPACE:\n",
        "      next_state = gridworld.get_next_state(state=key, action=action)\n",
        "      if next_state in actions.keys() or next_state in rewards.keys():\n",
        "        actions_.append(action)\n",
        "    actions[key] = tuple(actions_)\n",
        "\n",
        "  gridworld.set_actions(actions)\n",
        "  return gridworld"
      ],
      "metadata": {
        "id": "b4RqTitHEJcW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_negative_gridworld(step_cost=-0.1):\n",
        "  # in this game we want to try to minimize the number of moves\n",
        "  # so we will penalize every move\n",
        "  gridworld = create_gridworld()\n",
        "  for key, _ in gridworld.actions:\n",
        "    gridworld.rewards[key] = step_cost\n",
        "  return gridworld"
      ],
      "metadata": {
        "id": "GOaITlboES0Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_values(value_function, gridworld):\n",
        "  for i in range(gridworld.rows):\n",
        "    print(\"---------------------------\")\n",
        "    for j in range(gridworld.cols):\n",
        "      value = value_function.get((i,j), 0)\n",
        "      if value >= 0:\n",
        "        print(\" %.2f|\" % value, end=\"\")\n",
        "      else:\n",
        "        print(\"%.2f|\" % value, end=\"\") # -ve sign takes up an extra space\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "KC9-4xGmE_Cy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_policy(policy, gridworld):\n",
        "  for i in range(gridworld.rows):\n",
        "    print(\"---------------------------\")\n",
        "    for j in range(gridworld.cols):\n",
        "      state = (i, j)\n",
        "      action = policy.get(state, ' ')\n",
        "      print(\"  %s  |\" % action, end=\"\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "sKvENhEyE-4D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epsilon_greedy(policy, state, epsilon=0.1):\n",
        "  prob = np.random.random()\n",
        "  if prob < 1 - epsilon:\n",
        "    return policy[state]\n",
        "  else:\n",
        "    return np.random.choice(ACTION_SPACE)"
      ],
      "metadata": {
        "id": "1UCNf25evQu3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play_game(gridworld, policy, max_steps=20):\n",
        "  # We reset to the initial state\n",
        "  gridworld.reset()\n",
        "\n",
        "  state = gridworld.current_state()\n",
        "  action = epsilon_greedy(policy, state)\n",
        "\n",
        "  states = [state]\n",
        "  rewards = [0]\n",
        "  actions = [action]\n",
        "\n",
        "  steps = 0\n",
        "  while steps < max_steps:\n",
        "    reward = gridworld.move(action)\n",
        "    next_state = gridworld.current_state()\n",
        "\n",
        "    # update state and reward list\n",
        "    states.append(next_state)\n",
        "    rewards.append(reward)\n",
        "\n",
        "    if not gridworld.game_over():\n",
        "      action = epsilon_greedy(policy, state)\n",
        "      actions.append(action)\n",
        "    else:\n",
        "      break\n",
        "\n",
        "    steps += 1\n",
        "    state = next_state\n",
        "\n",
        "  return states, actions, rewards"
      ],
      "metadata": {
        "id": "I7QDMdo0PD0M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_dict(dict_):\n",
        "  max_val = max(dict_.values())\n",
        "  max_keys = [key for key, val in dict_.items() if val == max_val]\n",
        "  return np.random.choice(max_keys), max_val"
      ],
      "metadata": {
        "id": "OUMQiFe4g_UO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "  gridworld = create_gridworld()\n",
        "\n",
        "  # state -> action\n",
        "  # we'll randomly choose an action and update as we learn\n",
        "  policy = {}\n",
        "  for state in gridworld.actions.keys():\n",
        "    policy[state] = np.random.choice(ACTION_SPACE)\n",
        "\n",
        "  q_table = {}\n",
        "  sample_counts = {}\n",
        "  state_sample_count = {}\n",
        "  states = gridworld.all_states()\n",
        "\n",
        "  for state in states:\n",
        "    if state in gridworld.actions:\n",
        "      q_table[state] = {}\n",
        "      sample_counts[state] = {}\n",
        "      state_sample_count[state] = 0\n",
        "      for action in ACTION_SPACE:\n",
        "        q_table[state][action] = 0\n",
        "        sample_counts[state][action] = 0\n",
        "\n",
        "  deltas = []\n",
        "  for it in range(10000):\n",
        "    if it % 1000 == 0:\n",
        "      print(f\"Iteration: {it}\")\n",
        "\n",
        "    delta = 0\n",
        "    states, actions, rewards = play_game(gridworld, policy)\n",
        "    states_actions = list(zip(states, actions))\n",
        "\n",
        "    return_ = 0\n",
        "    rewards_ = rewards[1:]\n",
        "    for t in range(len(states) - 2, -1, -1):\n",
        "      reward = rewards[t + 1]\n",
        "      return_ = reward + DISCOUNT_FACTOR * return_\n",
        "      state = states[t]\n",
        "      action = actions[t]\n",
        "\n",
        "      # first-visit MC\n",
        "      if (state, action) not in states_actions[:t]:\n",
        "        old_q_value = q_table[state][action]\n",
        "        sample_counts[state][action] += 1\n",
        "        lr = 1 / sample_counts[state][action]\n",
        "        q_table[state][action] = old_q_value + lr * (return_ - old_q_value)\n",
        "\n",
        "        # update policy\n",
        "        policy[state] = max_dict(q_table[state])[0]\n",
        "\n",
        "        # update state_sample_count\n",
        "        state_sample_count[state] += 1\n",
        "\n",
        "        # update delta\n",
        "        delta = max(delta, np.abs(q_table[state][action] - old_q_value))\n",
        "\n",
        "    deltas.append(delta)\n",
        "\n",
        "  plt.plot(deltas)\n",
        "  plt.show();\n",
        "  # once we're done, print the final policy and values\n",
        "  print(\"policy:\")\n",
        "  print_policy(policy, gridworld)\n",
        "  print()\n",
        "  value_function_mc = {}\n",
        "  for state, q_values in q_table.items():\n",
        "    value_function_mc[state] = max_dict(q_table[state])[1]\n",
        "  print(\"values MC:\")\n",
        "  print_values(value_function_mc, gridworld)\n",
        "  print()\n",
        "\n",
        "  # We can see that as we go further and further away from what the policy dictates,\n",
        "  # the number of samples we collect gets smaller and smaller.\n",
        "  print(\"state_sample_count:\")\n",
        "  state_sample_count_arr = np.zeros((gridworld.rows, gridworld.cols))\n",
        "  for i in range(gridworld.rows):\n",
        "    for j in range(gridworld.cols):\n",
        "      if (i, j) in state_sample_count:\n",
        "        state_sample_count_arr[i,j] = state_sample_count[(i, j)]\n",
        "  df = pd.DataFrame(state_sample_count_arr)\n",
        "  print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fhZXEhZYufUK",
        "outputId": "dd3f24b7-7f76-48b4-b985-d1eeecf0753c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0\n",
            "Iteration: 1000\n",
            "Iteration: 2000\n",
            "Iteration: 3000\n",
            "Iteration: 4000\n",
            "Iteration: 5000\n",
            "Iteration: 6000\n",
            "Iteration: 7000\n",
            "Iteration: 8000\n",
            "Iteration: 9000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArUUlEQVR4nO3deXxU1cH/8e8kIQuahE0CSIBoUSyggihF1GrlkSJaafu4PdQfpbZaGytIfyr8FHcMpdaHqoiKLaBlEauAC6KILIIhgUCAAAYQQsKSsIRkspAQMuf3hzJmSIAE7pyZST7v12ter+TeM/eeOYSZ75x7zrkuY4wRAACAJWGBrgAAAGhaCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArIoIdAVO5PF4tHfvXsXGxsrlcgW6OgAAoB6MMSopKVGHDh0UFnbqvo2gCx979+5VYmJioKsBAADOQF5enjp27HjKMkEXPmJjYyV9V/m4uLgA1wYAANSH2+1WYmKi93P8VIIufBy/1BIXF0f4AAAgxNRnyAQDTgEAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVDQ4fy5cv16233qoOHTrI5XJp3rx5PvuNMXryySfVvn17xcTEaMCAAdq2bZtT9QUAACGuweGjrKxMl112mSZNmlTn/gkTJujll1/W66+/rrS0NJ1zzjkaOHCgKioqzrqyAAAg9DX43i6DBg3SoEGD6txnjNHEiRP1xBNP6LbbbpMkvf3220pISNC8efN01113nV1tAQBAyHN0zMfOnTuVn5+vAQMGeLfFx8erb9++Sk1NrfM5lZWVcrvdPg80TvMz9+jFz7LVZfQnemUxl+IAoKlyNHzk5+dLkhISEny2JyQkePedKCUlRfHx8d5HYmKik1VCkNhTdEQjZmfq1SXbJUl/X7RVeYXlAa4VACAQAj7bZcyYMSouLvY+8vLyAl0l+EFh6dHa28pqbwMANH6Oho927dpJkgoKCny2FxQUePedKCoqSnFxcT4PAADQeDkaPpKSktSuXTstXrzYu83tdistLU39+vVz8lQAACBENXi2S2lpqbZv3+79fefOncrMzFSrVq3UqVMnjRw5Us8//7y6du2qpKQkjR07Vh06dNCQIUOcrDcAAAhRDQ4fa9as0Q033OD9fdSoUZKkYcOGadq0aXr00UdVVlam++67T0VFRbrmmmu0cOFCRUdHO1drAAAQshocPq6//noZY0663+Vy6dlnn9Wzzz57VhUDAACNU8BnuwAAgKaF8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfCBgT6AoAAAKC8AEAAKwifAAAAKsIH7DC5Qp0DQAAwYLwASsMAzwAAN8jfCBg6AwBgKaJ8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwgYEygKwAACAjCBwAAsIrwAQAArCJ8AAAAqwgfsMLlCnQNAADBgvABAACsInwAAACrCB8AAMAqwgesMHUs6sEwEABomggfAADAKsIHAACwyvHwUV1drbFjxyopKUkxMTG68MIL9dxzz8nU1e8OAACanAinD/jXv/5VkydP1vTp09W9e3etWbNGw4cPV3x8vB566CGnTwcAAEKM4+Hj66+/1m233abBgwdLkrp06aJZs2YpPT3d6VMBAIAQ5Phll6uvvlqLFy/W1q1bJUnr16/XihUrNGjQoDrLV1ZWyu12+zwAAEDj5XjPx+jRo+V2u9WtWzeFh4erurpa48aN09ChQ+ssn5KSomeeecbpagAAgCDleM/HnDlzNGPGDM2cOVNr167V9OnT9eKLL2r69Ol1lh8zZoyKi4u9j7y8PKerBAAAgojjPR+PPPKIRo8erbvuukuS1LNnT+3atUspKSkaNmxYrfJRUVGKiopyuhoAACBIOd7zUV5errAw38OGh4fL4/E4fSoAABCCHO/5uPXWWzVu3Dh16tRJ3bt317p16/TSSy/pd7/7ndOnAgAAIcjx8PHKK69o7Nix+tOf/qT9+/erQ4cOuv/++/Xkk086fSoAABCCHA8fsbGxmjhxoiZOnOj0oQEAQCPAvV0AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPhAwJtAVAAAEBOEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+IAVLlegawAACBaEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDVpg6buTCBBgAaJoIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwgYAxga4AACAgCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAStcrkDXAAAQLAgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifCBgWPoDAJomwgesMCbQNQAABAvCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqv4SPPXv26De/+Y1at26tmJgY9ezZU2vWrPHHqQAAQIiJcPqAhw8fVv/+/XXDDTfo008/1Xnnnadt27apZcuWTp8KIY5FTwGgaXI8fPz1r39VYmKipk6d6t2WlJTk9GkAAECIcvyyy4cffqg+ffro9ttvV9u2bdWrVy9NmTLlpOUrKyvldrt9HgAAoPFyPHzs2LFDkydPVteuXfXZZ5/pgQce0EMPPaTp06fXWT4lJUXx8fHeR2JiotNVAgAAQcRljLP3G42MjFSfPn309ddfe7c99NBDWr16tVJTU2uVr6ysVGVlpfd3t9utxMREFRcXKy4uzsmqIYA27i7Wra+u8Nk2L7m/Lk9sEZgKAQAc5Xa7FR8fX6/Pb8d7Ptq3b68f//jHPtsuueQS5ebm1lk+KipKcXFxPg8AANB4OR4++vfvr+zsbJ9tW7duVefOnZ0+FQAACEGOh4+HH35Yq1at0gsvvKDt27dr5syZevPNN5WcnOz0qQAAQAhyPHxceeWVmjt3rmbNmqUePXroueee08SJEzV06FCnTwUAAEKQ4+t8SNItt9yiW265xR+HRohyuQJdAwBAsODeLgAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcChkVPAaBpInzACmMCXQMAQLAgfAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAobZtwDQNBE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWED1jhcgW6BgCAYEH4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwQMK64DQNNE+AAAAFYRPgAAgFWED1hhTKBrAAAIFoQPBEzlMY9GvZupTzbsC3RVAAAWET4QMNNTc/TBuj1Knrk20FUBAFhE+EDAHCipDHQVAAABQPgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPWOFy1bGRO90CQJPk9/Axfvx4uVwujRw50t+nAgAAIcCv4WP16tV64403dOmll/rzNAhVdfWGAAAaPb+Fj9LSUg0dOlRTpkxRy5Yt/XUaAAAQYvwWPpKTkzV48GANGDDglOUqKyvldrt9HgAAoPGK8MdBZ8+erbVr12r16tWnLZuSkqJnnnnGH9UAAABByPGej7y8PI0YMUIzZsxQdHT0acuPGTNGxcXF3kdeXp7TVQIAAEHE8Z6PjIwM7d+/X7179/Zuq66u1vLly/Xqq6+qsrJS4eHh3n1RUVGKiopyuhoAACBIOR4+brzxRm3cuNFn2/Dhw9WtWzc99thjPsEDAAA0PY6Hj9jYWPXo0cNn2znnnKPWrVvX2g4AAJoeVjgFAABW+WW2y4mWLl1q4zQAACAE0PMBAACsInwAAACrCB8AAMAqwgcAALCK8AErjAl0DQAAwYLwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8IHAYeExAGiSCB8AAMAqwgcAALCK8AErXK66NlqvBgAgCBA+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPhA4Ne7tkplXpPziisDVBQBgTUSgKwBI0pBJKyVJOeMHB7gmAAB/o+cDAABYRfgAAABWET4AAIBVhA8AAGAV4QOB4wp0BQAAgUD4AAAAVhE+AACAVYQPAABgFeEDVhhz+jJOOFRaqT1FR+ycDABwRljhFI3KFc9/IUla/+RNim/eLMC1AQDUhZ4PNEo5h8oCXQUAwEkQPhA4li7FAACCC+EDAABYRfgAAABWET4QOKxwCgBNEuEDAABYRfhAo8RYVgAIXoQPWOHiEgsA4HuEDzRKZB0ACF6EDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPBA7zYQGgSSJ8oFEi1wBA8CJ8AAAAqwgfAADAKsIHAsePK4GxyBgABC/CBwAAsMrx8JGSkqIrr7xSsbGxatu2rYYMGaLs7GynT4PGgFGhANAkOR4+li1bpuTkZK1atUqLFi1SVVWVbrrpJpWVlTl9KgAAEIIinD7gwoULfX6fNm2a2rZtq4yMDF133XVOnw5NxNSVO5XU5hxdf3HbepWnUwUAgpfj4eNExcXFkqRWrVrVub+yslKVlZXe391ut7+rhBCTsatQz3y0WZKUM35wgGsDADhbfh1w6vF4NHLkSPXv3189evSos0xKSori4+O9j8TERH9WCSFob1FFoKsAAHCQX8NHcnKysrKyNHv27JOWGTNmjIqLi72PvLw8f1YJwYT5sADQJPntssuDDz6ojz/+WMuXL1fHjh1PWi4qKkpRUVH+qgaaKHINAAQvx8OHMUZ//vOfNXfuXC1dulRJSUlOnwKNBaNCAaBJcjx8JCcna+bMmZo/f75iY2OVn58vSYqPj1dMTIzTpwMAACHG8TEfkydPVnFxsa6//nq1b9/e+3j33XedPhVCiLHcy0GnCgAEL79cdgEAADgZ7u2CwGFUKAA0SYQPBA6dZADQJBE+AACAVYQPBL0z6SDhig4ABC/CBwAAsIrwAStcdXRFpOcU1u+5Z3A+hpMAQPAifAAAAKsIHwAAwCrCBwAAsIrwgaAy6B9fyeMxGvrWKo2YvU4S4zcAoLEhfCCobNnn1jf5JVq5/ZDmZ+4NdHWAJqu4vEpTlu9QfnFFoKuCRojwgaDjOeH+QGcy24V1PoCz8+j76zVuwRbd+WZqoKuCRojwgUaJSzXA2VmafUCStOtQeYBrgsaI8AEAAKwifCDo1ezF2FN05OTlDP0dABAKCB8IKc9+tCnQVQAAnCXCB4LOqTowyo9W26sIAMAvCB8IKa66bhIDAAgphA8EPddJfgYAhCbCBwAAsIrwgaBjTlilgzksANC4ED4QUhjyAQChj/CBkHKq7MEyHwAQGggfCGpOLRz2dmqOhk9NV0WV3am6eYXlKj5SZfWcABDsCB8Iek5caXly/iYtyT6g2em5DhytfnYfLte1E5bosmc+t3ZOAAgFhA8EnVN1dpztOh9lFhcpy9h12Nq5ACCUED4Q9GpmkePRY8ryHfp8U/7Jn3OSBMOAVQAIvIhAVwBoqLW5hzVuwRZJUs74wQGuDQCgoej5gBVnOm70xOe5XNJ+d+Vpn+dyuVRYdlQeD1NggDNBLyH8ifCBoPP+2t3en9/8ascZHWN9XpF6P7dI905f7bPdxQLtQL0wdR3+RPhA0Hk7dZf35/GffnNCXDh5eKj5Xjn96xxJ0pLsA05WDQCsWJ1TqEf/s16Hy44Guip+wZgPBD2+gAFoam5/PVWSdMxj9NIdlwe2Mn5AzwdCytleh+Y6NlA//F8JDrsOlQe6Cn5B+IAVtt/Idhwss3tCoJFhzAf8ifAB+IExRmPnZQW6GgAQlAgfCCln24FiqwNmxfaDclccs3Q2AAgthA8EvZqBwanLN4VlR1VU7r9R5O4jBA+ENsZ8wJ+Y7YKg9/jcjd6fT3WH2PreAbfyWLV6P7dIkvTtCzcrPIx3WQCwiZ4PBL2aly8qj3nO6lgul3So9IcejyNV9m40B4QSBpzCnwgfCCmh2kdR316ZYHbkaLUWbS7QEYt3BgbQOBE+EFLW7y4OdBXOSKDrvXmvW/9v7kbtd1ec8TEefX+D/vD2Gv3f/6x3sGYAmiLCB0JKtcdobe7hQFejwdynGKtiw80vf6WZabn6y3tnHhw+Wr9XkvTJhn1OVQtBjAGn8CfCB0LOm8vP7GZzx2XtCc3eEyds2VcS6CogRDSCK4UIYoQPNCkuuXTfOxn2z2vhW2S1x8jj4RMDQPAjfAAOydhVqEfeW69DpZXWz13tMbrpf5dpyGsrTzO4lXASCqqqPXJXBPZSHeBPhA80Gif7WP3624P1PsayrQd03YQlSttxyGd7tceouPzUHwa/npyq9zJ266kPN9X7fE7JLSzXtwfKtGF3sY5Wn3w6Ml3poeHnE5fr0qc/1/6SMx8gfLYY8wF/Inyg0fufKWnen7P2nnq8x7B/pSu3sFx3vrnKZ/sdb6Tqsmc/165Dp79hXU4dZYLlQ99f1fh8U74+35Tvp6M3Pd8e+O5vaPnW+gdnNE6NNQMSPtCkzM/ce0bPy9j13QybeevO7Pmh5t3VuRoxe52qTtGLclxp5THd906G7nsnQ+VHWVa+sbAdmI8e82jMBxu1YCOzqZoCwgdC2qcb9+mfK3bq4XczVe3wYMuZablndP+XsspqHT7J8+asyWvQZSCn1Xexs8fe36j5mXs1b92e05atuehYZdXZrUCLpmvOmjzNSs/Vn2asDXRVYAH3dkFIe6DGG1X7+GhHj/3/5m7UR+v3atZ9P/Fuq8918J0Hy/TEvKxa2zfuLtaj/9kgScoZP9ixevrTqe6l0xDZ+SXq1Kq5YiLDHTke/M/2mI/9JfYHaoeCILli6zh6PtBovLb02wY/Z9i/0uXxGP1zxU79evLXtfannjDw9ES7DpXptaXbVVp5+ssNuw+X+/zurqhS5TFnliqfn/lDD8WpOjcC8Ub2xeYCDZy4XL98bWUAzm5PgbtC767OVQX3C4KDNu0tbhS3ZzgR4QNNWsauw5q/fo+e+3izd1xHQ/x84leasDBb4z7Z3KDnFR+p0qVPf67+479s8DnrMvGLbd6fK6s8uuefaXrrq9qLsZ3uPexASWWDPzzNaSLNB+t2S5K+yQ++Bc7KKo/pxc+yHVl4bsiklXrs/Y2asDDbgZoFXiA/7/4yZ70OBmDKejCqqPLo880Fga6G4wgfaPImN6DHpOzoMR2tcWfd43fFTdtReNrn1uzGzswrkiQdLK3fmJKjxzxanVOoNTmF2nia+8S8l5Gnr7Yd1POfbJEkzU7P9e4rPlKlwrLvzvnxhr0+S9XnFZbrynFf6GcvLq1XnepS1+dVMH9pe2nRVr26ZLtueWXFWR9rX/F302L/tXLnWR+rqXt/7W6NrePSZVP14fr6D3TP2lOs3EPlpy8YYIQPNHlbC0rrXfaNZTv0s78vlSTtKTri3d7Q69Wnu5w+P3OP1n8fUCTpqQ+zdPvrqfrv11N166srTjkLpeYlIHdFlUZ/sNFn/1XjvtCrX27TgzPX6Vev/XCpaenWA5KkvcWnX1tiYdaZz0io9hgNfWuVnv5+PZSDpZV6JzVHxUeqVFp5TJl5Rda6mTedZur1mUrfefowGuycGPNhjFF2fkm9Zk2daOfB009rbzLq+d+hwF2hW15Zoev+tsS/9XEA4QM4jRNvpLb78BEdPebRrTW+LddnzMfprMs9rAJ3hVZuP6gRszN126QfxkjMSs/zKbvzYJlueHGp3lm1q9Zxan5uX/r057X2H/MYvfj51h9+r/ZoTU6hT4/O6fzx33XPSNhW8MOllc825de6nLF4S4Ge/2SzVm4/pGlf50iS7p22WmPnb9K901ar97OLNGTSSj378Q+XsfIKy7V9v29ArE84Sd9ZqOQZa1Vwijv5nmnGqaiqPuW04hMXqWuq/r1qlwZOXK4/z1wX6Ko02OItBXonNafBz9u+v/Ss7h59Nr49UP8vUoHGbBfgNJJn1v6gveiJTxt0jCXZ+9Wncyvv79U1PvUOlFSqwF2hX75We8Drydz0v8slSWPnZemen3T22dfQz9O/LvxGU75q+KWCao9ReJjv1+M731ylnPGDlbWnWPd/fw+dQT3aefffO32NT/khk1Zq/feXkdbUGHMzdWWOnrq1u4wxunbCd9/iNjx9kxZs2KdpX+fom/wS/eOuy3Xb5efXqtf2/aXKOVim37/93bk+2bhPOeMHq7i8SvHNm3nLjZqTqbQaPRRHjlb7zMaZsnyH3li+Qx8+2F8dWsR4t3s8Rpc+/bmOVnu09flB2n243Ge/9F3AC5S6/l3OhBOdT298fxPIhSG4AN3xv9XenVuqe4f4ej0nv7hCA15aJqlhM9rKKo/pt1PTNbB7O/3+2gtqFzjhn3PVjkO6681Vev+Bfrri+/eVg6WVmrM6r/Zzg5Tfej4mTZqkLl26KDo6Wn379lV6erq/TgUEvakrc3zGAgyfutr785XjvjjpmIN3Vu067T0+xpxwWeXlxdtOUrJupwoexzzmpNePj/dc1JV2avZUfJp18g+ezBqXlk40dl6Wzwym3EPlGv3BRu/A1RGzM+t83oCXlnmDx3F3v7lKlz37uT79fgErY4w+WOu7hsnfP89WRVW1t1dl3IItOlhaqavHf6kuoz/xDsTNd1d4l7D/xasr9LO/L1O3sQt9jnV8zZm0HYd0zz/T9PSHm/R+xm49/eEmdRn9ib44YQDhln1urcs9rB0HSjV86g/vlRm7CvX0h5v09faDKio/qh0HSr31OFbtUXZ+ibL2FHvPN/GLrbrsmc+1fX/JaWdSnewmhCe7lcDZXgrL2lNs7caH9a1rfcrVvKS6OqdQfV/4wvt3dKIt+e76VfAE01NztDrnsHecVu2K+v561/crMP96cqp329ApaZp3hosoBoJfej7effddjRo1Sq+//rr69u2riRMnauDAgcrOzlbbtm39cUog6J3JbJqx87JOO/BuVo0BpU4b/+k3Gv/pN3p+SI9a+577eLM273Xr/bW7fbZ3Gf2JI+c+8ZLS3hpjbI7LL67QlK92KDzMpdsu76D/XVR38Do+ZfqpDzfpis4t9dGG2h8eb63YqbdW7NQdfTpq/K8urbV/0pLtuuuqTj4zlE42g6faGO0rPuJdpv+rbb4Ly/3+7TXeb8bvpOZo7Py67wd0/HKbN+hJujghVp89fJ1GvJvpc0nw2xdu9s56GvDSdz1j7973E0WEu3RuVDM9+v4G9egQp3G/7KmFWfn6y5xMPf2L7np92bc6NypCI//rIj00a51KKmpfTnpl8TZNT92lv99xmX560Xne7YdKKxUTGa6hb6VpXW6RJGlnys2qqPLUWtPllldW6PGbL9GQXufr//wrXbFREfrnb/to+/5Svbs6T7NP+Naec6hMKQu26N5rk9Q2NlrvZ+zWOVHh+nmP9pKk/SUVmr9ur/77io5qeU6kpO+mvt82aaXOiYzQrD/8ROk5hRrUo53Oiar9Ufebt9K0YvtBzbm/n8bOy1J2QYmu7dpGbw3ro6iIH+q+emehWsQ00+WJLTR86mqVVh7TAzPW+vRsTFu5U5cmttCMGn+zm/e6VXmsWufFRql5ZISOVFWrXVy0t1fK4zE6Wu1RZHjYadfTKTt6zPslJC66WZ1lsgt8/xaNMdp1qFydWzeXKwhv1OMyfhjZ1bdvX1155ZV69dVXJUkej0eJiYn685//rNGjR5/yuW63W/Hx8SouLlZcXJzTVUOAZO0pdmRGAdBYdGwZo591a6u3U2uP2zkTnVo1V25h8M9yqKl9fLR3ltDJRIaH6e6rEjX9+3a6+6rEWmOgBvdsr09OsSz7+w9crdzCMs1Oz1PazkLFxzQ75Qd+dLMwVZywWm/rcyJ1qMx3dlpsdIR6dIg/7XpANc38Q1+f+02daMJ/X6odB8r0+rL6zcJb/9RN2rC7SPf80/fqwhWdW3q/8Iz6r4t0acd4zUrPVVKbczV33W5N+p/e6tOlVV2HPGMN+fx2PHwcPXpUzZs313/+8x8NGTLEu33YsGEqKirS/PnzfcpXVlaqsvKHbi23263ExETHw8fB0kpNWrLdseOhYfYWHdFnm37oam4bG6VR/3VRrZkYAAA7to0bpGbhzo2+aEj4cPyyy8GDB1VdXa2EhASf7QkJCfrmm29qlU9JSdEzzzzjdDVqcR+p0tSVOX4/D+rnt/276K6rOik+ppkemLFW/S5o3aBvDwCAsxPhwMDkMz53wM78vTFjxmjUqFHe34/3fDitRfNIJd9woePHRf0t33pQG/cUKyoiTL+/5rsR3YN6tvdeOzXG+FybrPYYVVV7FB7m0uGyowoLcyn120O6pH2scgvLFRURrqXZ++VyufTlN/tVVe3RTy86T4VlR5XYqrm2FZTqiy0F6t2phdrHx+hXvc+vNduipnZx0cp3VygizKUnBl+ipz+qe9XSO/p0VHZBqc86HA3hcgX3wlsAGr8Hrr8woGNBAn7Z5USM+QAAIPQ05PPb8am2kZGRuuKKK7R48WLvNo/Ho8WLF6tfv35Onw4AAIQYv1x2GTVqlIYNG6Y+ffroqquu0sSJE1VWVqbhw4f743QAACCE+CV83HnnnTpw4ICefPJJ5efn6/LLL9fChQtrDUIFAABNj1/W+TgbjPkAACD0BHTMBwAAwKkQPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABW+WV59bNxfMFVt9sd4JoAAID6Ov65XZ+F04MufJSUlEiSEhMTA1wTAADQUCUlJYqPjz9lmaC7t4vH49HevXsVGxsrl8vl6LHdbrcSExOVl5fHfWP8iHa2g3a2g3a2h7a2w1/tbIxRSUmJOnTooLCwU4/qCLqej7CwMHXs2NGv54iLi+MP2wLa2Q7a2Q7a2R7a2g5/tPPpejyOY8ApAACwivABAACsalLhIyoqSk899ZSioqICXZVGjXa2g3a2g3a2h7a2IxjaOegGnAIAgMatSfV8AACAwCN8AAAAqwgfAADAKsIHAACwqsmEj0mTJqlLly6Kjo5W3759lZ6eHugqBbWUlBRdeeWVio2NVdu2bTVkyBBlZ2f7lKmoqFBycrJat26tc889V7/+9a9VUFDgUyY3N1eDBw9W8+bN1bZtWz3yyCM6duyYT5mlS5eqd+/eioqK0o9+9CNNmzbN3y8vKI0fP14ul0sjR470bqONnbNnzx795je/UevWrRUTE6OePXtqzZo13v3GGD355JNq3769YmJiNGDAAG3bts3nGIWFhRo6dKji4uLUokUL3XvvvSotLfUps2HDBl177bWKjo5WYmKiJkyYYOX1BYPq6mqNHTtWSUlJiomJ0YUXXqjnnnvO514ftHPDLV++XLfeeqs6dOggl8ulefPm+ey32abvvfeeunXrpujoaPXs2VMLFiw4sxdlmoDZs2ebyMhI869//cts2rTJ/OEPfzAtWrQwBQUFga5a0Bo4cKCZOnWqycrKMpmZmebmm282nTp1MqWlpd4yf/zjH01iYqJZvHixWbNmjfnJT35irr76au/+Y8eOmR49epgBAwaYdevWmQULFpg2bdqYMWPGeMvs2LHDNG/e3IwaNcps3rzZvPLKKyY8PNwsXLjQ6usNtPT0dNOlSxdz6aWXmhEjRni308bOKCwsNJ07dza//e1vTVpamtmxY4f57LPPzPbt271lxo8fb+Lj4828efPM+vXrzS9+8QuTlJRkjhw54i3z85//3Fx22WVm1apV5quvvjI/+tGPzN133+3dX1xcbBISEszQoUNNVlaWmTVrlomJiTFvvPGG1dcbKOPGjTOtW7c2H3/8sdm5c6d57733zLnnnmv+8Y9/eMvQzg23YMEC8/jjj5sPPvjASDJz58712W+rTVeuXGnCw8PNhAkTzObNm80TTzxhmjVrZjZu3Njg19QkwsdVV11lkpOTvb9XV1ebDh06mJSUlADWKrTs37/fSDLLli0zxhhTVFRkmjVrZt577z1vmS1bthhJJjU11Rjz3X+YsLAwk5+f7y0zefJkExcXZyorK40xxjz66KOme/fuPue68847zcCBA/39koJGSUmJ6dq1q1m0aJH56U9/6g0ftLFzHnvsMXPNNdecdL/H4zHt2rUzf/vb37zbioqKTFRUlJk1a5YxxpjNmzcbSWb16tXeMp9++qlxuVxmz549xhhjXnvtNdOyZUtv2x8/98UXX+z0SwpKgwcPNr/73e98tv3qV78yQ4cONcbQzk44MXzYbNM77rjDDB482Kc+ffv2Nffff3+DX0ejv+xy9OhRZWRkaMCAAd5tYWFhGjBggFJTUwNYs9BSXFwsSWrVqpUkKSMjQ1VVVT7t2q1bN3Xq1MnbrqmpqerZs6cSEhK8ZQYOHCi3261NmzZ5y9Q8xvEyTenfJjk5WYMHD67VDrSxcz788EP16dNHt99+u9q2batevXppypQp3v07d+5Ufn6+TzvFx8erb9++Pm3dokUL9enTx1tmwIABCgsLU1pamrfMddddp8jISG+ZgQMHKjs7W4cPH/b3ywy4q6++WosXL9bWrVslSevXr9eKFSs0aNAgSbSzP9hsUyffSxp9+Dh48KCqq6t93pwlKSEhQfn5+QGqVWjxeDwaOXKk+vfvrx49ekiS8vPzFRkZqRYtWviUrdmu+fn5dbb78X2nKuN2u3XkyBF/vJygMnv2bK1du1YpKSm19tHGztmxY4cmT56srl276rPPPtMDDzyghx56SNOnT5f0Q1ud6n0iPz9fbdu29dkfERGhVq1aNejfozEbPXq07rrrLnXr1k3NmjVTr169NHLkSA0dOlQS7ewPNtv0ZGXOpM2D7q62CD7JycnKysrSihUrAl2VRiUvL08jRozQokWLFB0dHejqNGoej0d9+vTRCy+8IEnq1auXsrKy9Prrr2vYsGEBrl3jMWfOHM2YMUMzZ85U9+7dlZmZqZEjR6pDhw60M3w0+p6PNm3aKDw8vNYMgYKCArVr1y5AtQodDz74oD7++GMtWbJEHTt29G5v166djh49qqKiIp/yNdu1Xbt2dbb78X2nKhMXF6eYmBinX05QycjI0P79+9W7d29FREQoIiJCy5Yt08svv6yIiAglJCTQxg5p3769fvzjH/tsu+SSS5Sbmyvph7Y61ftEu3bttH//fp/9x44dU2FhYYP+PRqzRx55xNv70bNnT91zzz16+OGHvT17tLPzbLbpycqcSZs3+vARGRmpK664QosXL/Zu83g8Wrx4sfr16xfAmgU3Y4wefPBBzZ07V19++aWSkpJ89l9xxRVq1qyZT7tmZ2crNzfX2679+vXTxo0bff7oFy1apLi4OO8HQb9+/XyOcbxMU/i3ufHGG7Vx40ZlZmZ6H3369NHQoUO9P9PGzujfv3+tqeJbt25V586dJUlJSUlq166dTzu53W6lpaX5tHVRUZEyMjK8Zb788kt5PB717dvXW2b58uWqqqryllm0aJEuvvhitWzZ0m+vL1iUl5crLMz3YyU8PFwej0cS7ewPNtvU0feSBg9RDUGzZ882UVFRZtq0aWbz5s3mvvvuMy1atPCZIQBfDzzwgImPjzdLly41+/bt8z7Ky8u9Zf74xz+aTp06mS+//NKsWbPG9OvXz/Tr18+7//g00JtuuslkZmaahQsXmvPOO6/OaaCPPPKI2bJli5k0aVKTmwZaU83ZLsbQxk5JT083ERERZty4cWbbtm1mxowZpnnz5ubf//63t8z48eNNixYtzPz5882GDRvMbbfdVud0xV69epm0tDSzYsUK07VrV5/pikVFRSYhIcHcc889Jisry8yePds0b9680U4BPdGwYcPM+eef751q+8EHH5g2bdqYRx991FuGdm64kpISs27dOrNu3Tojybz00ktm3bp1ZteuXcYYe226cuVKExERYV588UWzZcsW89RTTzHV9nReeeUV06lTJxMZGWmuuuoqs2rVqkBXKahJqvMxdepUb5kjR46YP/3pT6Zly5amefPm5pe//KXZt2+fz3FycnLMoEGDTExMjGnTpo35y1/+YqqqqnzKLFmyxFx++eUmMjLSXHDBBT7naGpODB+0sXM++ugj06NHDxMVFWW6detm3nzzTZ/9Ho/HjB071iQkJJioqChz4403muzsbJ8yhw4dMnfffbc599xzTVxcnBk+fLgpKSnxKbN+/XpzzTXXmKioKHP++eeb8ePH+/21BQu3221GjBhhOnXqZKKjo80FF1xgHn/8cZ/pm7Rzwy1ZsqTO9+Nhw4YZY+y26Zw5c8xFF11kIiMjTffu3c0nn3xyRq/JZUyNpecAAAD8rNGP+QAAAMGF8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMCq/w+Z9B2BQxko/QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy:\n",
            "---------------------------\n",
            "     |     |  D  |     |     |  D  |  D  |  D  |  D  |  U  |\n",
            "---------------------------\n",
            "  L  |  D  |  D  |  D  |  U  |     |  U  |     |     |     |\n",
            "---------------------------\n",
            "  D  |  L  |  U  |     |  D  |  L  |  D  |  U  |  L  |  L  |\n",
            "---------------------------\n",
            "     |  D  |  R  |  D  |     |     |  D  |  L  |     |  U  |\n",
            "---------------------------\n",
            "     |  U  |     |     |     |  D  |     |  D  |  U  |     |\n",
            "---------------------------\n",
            "  D  |     |     |     |  D  |     |  R  |  D  |  L  |     |\n",
            "---------------------------\n",
            "  L  |  U  |     |  R  |  R  |  R  |  D  |  D  |  L  |  L  |\n",
            "---------------------------\n",
            "  R  |     |  R  |  U  |     |     |  R  |     |     |  L  |\n",
            "---------------------------\n",
            "     |  R  |  U  |     |  U  |     |  U  |     |  L  |     |\n",
            "---------------------------\n",
            "  R  |  R  |  U  |     |     |     |     |  R  |     |  U  |\n",
            "\n",
            "values MC:\n",
            "---------------------------\n",
            " 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00|\n",
            "---------------------------\n",
            " 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00|\n",
            "---------------------------\n",
            " 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00|\n",
            "---------------------------\n",
            " 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00|\n",
            "---------------------------\n",
            " 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00|\n",
            "---------------------------\n",
            " 0.00| 0.00| 0.00| 0.00| 1.46| 0.00| 2.19| 7.03| 0.35| 0.00|\n",
            "---------------------------\n",
            " 0.00| 0.00| 0.00| 3.61| 4.08| 4.64| 5.37| 10.00| 3.34| 0.47|\n",
            "---------------------------\n",
            " 0.00| 0.00| 2.28| 2.87| 0.00| 0.00| 10.00| 0.00| 0.00| 0.00|\n",
            "---------------------------\n",
            " 0.00| 0.84| 1.81| 0.00| 0.00| 0.00| 1.79| 0.00| 0.00| 0.00|\n",
            "---------------------------\n",
            " 1.03| 1.23| 1.61| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00|\n",
            "\n",
            "state_sample_count:\n",
            "         0        1        2        3       4       5       6       7       8  \\\n",
            "0      0.0      0.0      0.0      0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "1      0.0      0.0      0.0      0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "2      0.0      0.0      0.0      0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "3      0.0      0.0      0.0      0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "4      0.0      0.0      0.0      0.0     0.0     0.0     0.0    14.0     9.0   \n",
            "5      0.0      0.0      0.0      0.0   453.0     0.0   345.0   432.0   220.0   \n",
            "6      0.0      0.0      0.0  16075.0  8570.0  8362.0  9856.0  9558.0  5855.0   \n",
            "7      0.0      0.0  16523.0  16353.0     0.0     0.0  1740.0     0.0     0.0   \n",
            "8      0.0   1804.0  10280.0      0.0     0.0     0.0   324.0     0.0     0.0   \n",
            "9  12717.0  10525.0  16448.0      0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "       9  \n",
            "0    0.0  \n",
            "1    0.0  \n",
            "2    0.0  \n",
            "3    0.0  \n",
            "4    0.0  \n",
            "5    0.0  \n",
            "6  141.0  \n",
            "7    5.0  \n",
            "8    0.0  \n",
            "9    0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4PUdzgQTwwpo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}